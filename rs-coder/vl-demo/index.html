<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Qwen2.5-VL + Piper TTS Demo</title>
    <style>
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #1a1a2e;
            color: #eee;
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
        }

        h1 {
            text-align: center;
            margin-bottom: 20px;
            color: #00d4ff;
        }

        .main-layout {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
        }

        .panel {
            background: #16213e;
            border-radius: 12px;
            padding: 20px;
            border: 1px solid #0f3460;
        }

        .panel h2 {
            margin-bottom: 15px;
            color: #00d4ff;
            font-size: 1.2rem;
        }

        .video-container {
            position: relative;
            background: #000;
            border-radius: 8px;
            overflow: hidden;
            aspect-ratio: 4/3;
        }

        #webcam {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }

        #canvas {
            display: none;
        }

        .snapshot-preview {
            margin-top: 10px;
            text-align: center;
        }

        #snapshot {
            max-width: 200px;
            border-radius: 4px;
            border: 2px solid #0f3460;
        }

        .controls {
            margin-top: 15px;
        }

        .control-group {
            margin-bottom: 15px;
        }

        .control-group label {
            display: block;
            margin-bottom: 5px;
            color: #aaa;
            font-size: 0.9rem;
        }

        textarea {
            width: 100%;
            padding: 12px;
            border: 1px solid #0f3460;
            border-radius: 8px;
            background: #1a1a2e;
            color: #eee;
            font-size: 14px;
            resize: vertical;
            min-height: 80px;
        }

        textarea:focus {
            outline: none;
            border-color: #00d4ff;
        }

        input[type="text"], input[type="number"], select {
            width: 100%;
            padding: 10px 12px;
            border: 1px solid #0f3460;
            border-radius: 8px;
            background: #1a1a2e;
            color: #eee;
            font-size: 14px;
        }

        input:focus, select:focus {
            outline: none;
            border-color: #00d4ff;
        }

        .button-row {
            display: flex;
            gap: 10px;
            margin-top: 15px;
        }

        button {
            flex: 1;
            padding: 12px 20px;
            border: none;
            border-radius: 8px;
            font-size: 14px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.2s;
        }

        .btn-primary {
            background: #00d4ff;
            color: #1a1a2e;
        }

        .btn-primary:hover {
            background: #00b8e6;
        }

        .btn-primary:disabled {
            background: #555;
            color: #888;
            cursor: not-allowed;
        }

        .btn-secondary {
            background: #0f3460;
            color: #eee;
        }

        .btn-secondary:hover {
            background: #1a4a7a;
        }

        .btn-danger {
            background: #e94560;
            color: #fff;
        }

        .btn-danger:hover {
            background: #d63050;
        }

        .btn-success {
            background: #00c853;
            color: #fff;
        }

        .btn-success:hover {
            background: #00a844;
        }

        .autosend-controls {
            display: flex;
            align-items: center;
            gap: 10px;
            margin-top: 10px;
        }

        .autosend-controls input[type="number"] {
            width: 100px;
        }

        .autosend-controls span {
            color: #aaa;
            font-size: 0.9rem;
        }

        .response-panel {
            display: flex;
            flex-direction: column;
            height: 100%;
        }

        .response-box {
            flex: 1;
            background: #1a1a2e;
            border: 1px solid #0f3460;
            border-radius: 8px;
            padding: 15px;
            overflow-y: auto;
            min-height: 200px;
            max-height: 350px;
            white-space: pre-wrap;
            font-family: 'Monaco', 'Menlo', monospace;
            font-size: 14px;
            line-height: 1.5;
        }

        .status-bar {
            margin-top: 15px;
            padding: 10px;
            background: #1a1a2e;
            border-radius: 8px;
            font-size: 0.85rem;
            color: #888;
        }

        .status-bar.error {
            color: #e94560;
            background: rgba(233, 69, 96, 0.1);
        }

        .status-bar.success {
            color: #00c853;
            background: rgba(0, 200, 83, 0.1);
        }

        .status-bar.loading {
            color: #00d4ff;
            background: rgba(0, 212, 255, 0.1);
        }

        .config-row {
            display: flex;
            gap: 15px;
            margin-bottom: 15px;
        }

        .config-row .control-group {
            flex: 1;
            margin-bottom: 0;
        }

        .streaming-indicator {
            display: inline-block;
            width: 8px;
            height: 8px;
            background: #00c853;
            border-radius: 50%;
            margin-right: 8px;
            animation: pulse 1s infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        .hidden {
            display: none !important;
        }

        /* Debug Stats Panel */
        .debug-panel {
            margin-top: 15px;
            background: #0d1b2a;
            border: 1px solid #1b4332;
            border-radius: 8px;
            padding: 15px;
        }

        .debug-panel h3 {
            color: #52b788;
            font-size: 0.95rem;
            margin-bottom: 12px;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .debug-panel h3::before {
            content: '';
            display: inline-block;
            width: 8px;
            height: 8px;
            background: #52b788;
            border-radius: 50%;
        }

        .stats-grid {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 10px;
        }

        .stat-item {
            background: #1a1a2e;
            padding: 10px;
            border-radius: 6px;
            border: 1px solid #0f3460;
        }

        .stat-label {
            font-size: 0.7rem;
            color: #888;
            text-transform: uppercase;
            letter-spacing: 0.5px;
            margin-bottom: 4px;
        }

        .stat-value {
            font-size: 1rem;
            font-weight: 600;
            color: #00d4ff;
            font-family: 'Monaco', 'Menlo', monospace;
        }

        .stat-value.highlight {
            color: #52b788;
        }

        .stat-value.warning {
            color: #ffc107;
        }

        .stat-value.error {
            color: #e94560;
        }

        /* Avatar Panel */
        .avatar-container {
            display: flex;
            justify-content: center;
            align-items: center;
            background: #1a1a2e;
            border-radius: 16px;
            padding: 15px;
            margin-bottom: 15px;
            min-height: 220px;
        }

        .avatar-svg {
            width: 130px;
            height: 195px;
            border-radius: 12px;
            filter: drop-shadow(0 4px 12px rgba(0,0,0,0.4));
        }

        /* TTS Panel */
        .tts-panel {
            margin-top: 15px;
            background: #1a0d2e;
            border: 1px solid #4a1b6d;
            border-radius: 8px;
            padding: 15px;
        }

        .tts-panel h3 {
            color: #b388ff;
            font-size: 0.95rem;
            margin-bottom: 12px;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .tts-panel h3::before {
            content: 'ðŸ”Š';
            font-size: 1rem;
        }

        .tts-controls {
            display: flex;
            gap: 10px;
            align-items: center;
            flex-wrap: wrap;
        }

        .tts-controls label {
            color: #aaa;
            font-size: 0.85rem;
        }

        .tts-controls input[type="checkbox"] {
            width: 18px;
            height: 18px;
            cursor: pointer;
        }

        .tts-controls select {
            width: auto;
            min-width: 120px;
        }

        .tts-status {
            margin-top: 10px;
            font-size: 0.85rem;
            color: #b388ff;
        }

        .tts-status.speaking {
            color: #00c853;
        }

        .tts-status.error {
            color: #e94560;
        }

        .audio-queue {
            margin-top: 10px;
            display: flex;
            gap: 5px;
            flex-wrap: wrap;
        }

        .audio-chunk {
            background: #4a1b6d;
            padding: 4px 8px;
            border-radius: 4px;
            font-size: 0.75rem;
            color: #b388ff;
        }

        .audio-chunk.playing {
            background: #00c853;
            color: #fff;
        }

        .audio-chunk.queued {
            background: #0f3460;
            color: #888;
        }

        .resolution-select {
            display: flex;
            gap: 10px;
            align-items: center;
        }

        .resolution-select select {
            flex: 1;
        }

        .resolution-info {
            font-size: 0.8rem;
            color: #888;
            margin-top: 5px;
        }

        @media (max-width: 900px) {
            .main-layout {
                grid-template-columns: 1fr;
            }
            .stats-grid {
                grid-template-columns: repeat(2, 1fr);
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Qwen2.5-VL + Piper TTS Demo</h1>

        <div class="config-row">
            <div class="control-group">
                <label for="apiUrl">VLM API Endpoint</label>
                <input type="text" id="apiUrl" value="">
            </div>
            <div class="control-group">
                <label for="ttsUrl">TTS API Endpoint</label>
                <input type="text" id="ttsUrl" value="">
            </div>
            <div class="control-group">
                <label for="modelName">Model Name</label>
                <input type="text" id="modelName" value="Qwen/Qwen2.5-VL-7B-Instruct">
            </div>
        </div>

        <div class="main-layout">
            <div class="panel">
                <h2>Camera Input</h2>
                <div class="video-container">
                    <video id="webcam" autoplay playsinline></video>
                </div>
                <canvas id="canvas"></canvas>

                <div class="snapshot-preview">
                    <img id="snapshot" class="hidden" alt="Last captured frame">
                </div>

                <div class="controls">
                    <div class="control-group">
                        <label for="cameraSelect">Camera</label>
                        <select id="cameraSelect">
                            <option value="">Loading cameras...</option>
                        </select>
                    </div>

                    <div class="control-group">
                        <label for="resolution">Image Resolution</label>
                        <div class="resolution-select">
                            <select id="resolution">
                                <option value="320x240">320x240 (QVGA) - Fastest</option>
                                <option value="640x480" selected>640x480 (VGA) - Balanced</option>
                                <option value="800x600">800x600 (SVGA)</option>
                                <option value="1280x720">1280x720 (HD 720p)</option>
                                <option value="1920x1080">1920x1080 (Full HD)</option>
                            </select>
                        </div>
                        <div class="resolution-info" id="resolutionInfo">Current: 640x480 | Est. payload: ~50KB</div>
                    </div>

                    <div class="control-group">
                        <label for="prompt">Prompt</label>
                        <textarea id="prompt" placeholder="Describe what you see in the image...">What do you see in this image? Describe it in one or two sentences.</textarea>
                    </div>

                    <div class="button-row">
                        <button id="sendBtn" class="btn-primary">Send</button>
                        <button id="autosendBtn" class="btn-success">Start Autosend</button>
                    </div>

                    <div class="autosend-controls">
                        <label for="interval">Interval:</label>
                        <input type="number" id="interval" value="5000" min="500" step="100">
                        <span>ms</span>
                    </div>
                </div>
            </div>

            <div class="panel response-panel">
                <h2>LLM Response</h2>

                <!-- Animated Avatar (rendered by avatar.js) -->
                <div class="avatar-container" id="avatarContainer">
                    <!-- Avatar will be inserted here by JavaScript -->
                </div>

                <div id="response" class="response-box">Waiting for input...</div>
                <div id="status" class="status-bar">Ready</div>

                <!-- TTS Panel -->
                <div class="tts-panel">
                    <h3>Text-to-Speech</h3>
                    <div class="tts-controls">
                        <input type="checkbox" id="ttsEnabled" checked>
                        <label for="ttsEnabled">Enable TTS</label>

                        <input type="checkbox" id="ttsStreaming" checked>
                        <label for="ttsStreaming">Stream (speak while generating)</label>

                        <button id="stopTtsBtn" class="btn-secondary" style="flex: 0; padding: 8px 16px;">Stop</button>
                        <button id="unlockAudioBtn" class="btn-success" style="flex: 0; padding: 8px 16px;">Unlock Audio</button>
                        <button id="testAudioBtn" class="btn-primary" style="flex: 0; padding: 8px 16px;">Test TTS</button>
                    </div>
                    <div class="tts-status" id="ttsStatus">TTS ready</div>
                    <div id="audioUnlockStatus" style="font-size: 0.8rem; color: #888; margin-top: 5px;"></div>
                    <div class="audio-queue" id="audioQueue"></div>
                </div>

                <!-- Debug Stats Panel -->
                <div class="debug-panel">
                    <h3>Performance Stats</h3>
                    <div class="stats-grid">
                        <div class="stat-item">
                            <div class="stat-label">Time to First Token</div>
                            <div class="stat-value" id="statTTFT">--</div>
                        </div>
                        <div class="stat-item">
                            <div class="stat-label">Total Latency</div>
                            <div class="stat-value" id="statLatency">--</div>
                        </div>
                        <div class="stat-item">
                            <div class="stat-label">Tokens/Second</div>
                            <div class="stat-value" id="statTPS">--</div>
                        </div>
                        <div class="stat-item">
                            <div class="stat-label">TTS Latency</div>
                            <div class="stat-value" id="statTTSLatency">--</div>
                        </div>
                        <div class="stat-item">
                            <div class="stat-label">Sentences Spoken</div>
                            <div class="stat-value highlight" id="statSentences">0</div>
                        </div>
                        <div class="stat-item">
                            <div class="stat-label">Request Count</div>
                            <div class="stat-value highlight" id="statRequests">0</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Avatar library for animated character -->
    <script src="avatar.js"></script>
    <script>
        // DOM Elements
        const webcam = document.getElementById('webcam');
        const canvas = document.getElementById('canvas');
        const snapshot = document.getElementById('snapshot');
        const promptInput = document.getElementById('prompt');
        const responseBox = document.getElementById('response');
        const statusBar = document.getElementById('status');
        const sendBtn = document.getElementById('sendBtn');
        const autosendBtn = document.getElementById('autosendBtn');
        const intervalInput = document.getElementById('interval');
        const apiUrlInput = document.getElementById('apiUrl');
        const ttsUrlInput = document.getElementById('ttsUrl');
        const modelNameInput = document.getElementById('modelName');
        const resolutionSelect = document.getElementById('resolution');
        const resolutionInfo = document.getElementById('resolutionInfo');
        const cameraSelect = document.getElementById('cameraSelect');

        // TTS elements
        const ttsEnabled = document.getElementById('ttsEnabled');
        const ttsStreaming = document.getElementById('ttsStreaming');
        const ttsStatus = document.getElementById('ttsStatus');
        const audioQueue = document.getElementById('audioQueue');
        const stopTtsBtn = document.getElementById('stopTtsBtn');
        const unlockAudioBtn = document.getElementById('unlockAudioBtn');
        const testAudioBtn = document.getElementById('testAudioBtn');
        const audioUnlockStatus = document.getElementById('audioUnlockStatus');

        // Stats elements
        const statTTFT = document.getElementById('statTTFT');
        const statLatency = document.getElementById('statLatency');
        const statTPS = document.getElementById('statTPS');
        const statTTSLatency = document.getElementById('statTTSLatency');
        const statSentences = document.getElementById('statSentences');
        const statRequests = document.getElementById('statRequests');

        // State
        let stream = null;
        let autosendInterval = null;
        let isAutosending = false;
        let isProcessing = false;
        let requestCount = 0;
        let sentenceCount = 0;
        let currentResolution = { width: 640, height: 480 };
        let selectedDeviceId = null;

        // TTS State
        let ttsAudioQueue = [];
        let isPlayingAudio = false;
        let currentAudio = null;
        let pendingSentence = '';
        let failedAudioQueue = []; // Store failed audio queue for retry after unlock
        let ttsSequenceNumber = 0; // Monotonic sequence for ordering
        let nextExpectedSequence = 0; // Next sequence number to play
        let pendingAudioItems = new Map(); // Out-of-order items waiting to be queued

        // Avatar instance (created during init)
        let avatar = null;

        // Resolution presets
        const resolutionPresets = {
            '320x240': { width: 320, height: 240, estKB: 15 },
            '640x480': { width: 640, height: 480, estKB: 50 },
            '800x600': { width: 800, height: 600, estKB: 80 },
            '1280x720': { width: 1280, height: 720, estKB: 150 },
            '1920x1080': { width: 1920, height: 1080, estKB: 300 }
        };

        // ==================== Audio Unlock Functions ====================

        // Explicit audio unlock for mobile browsers
        async function unlockAudio() {
            try {
                audioUnlockStatus.textContent = 'Unlocking audio...';
                audioUnlockStatus.style.color = '#ffc107';

                // Initialize avatar's audio context
                avatar.initAudioContext();

                // Resume if suspended
                if (avatar.audioContext.state === 'suspended') {
                    await avatar.audioContext.resume();
                }

                // Play a silent buffer to fully unlock audio
                const buffer = avatar.audioContext.createBuffer(1, 1, 22050);
                const source = avatar.audioContext.createBufferSource();
                source.buffer = buffer;
                source.connect(avatar.audioContext.destination);
                source.start(0);

                // Create an oscillator and play it briefly (works better on Chrome)
                const oscillator = avatar.audioContext.createOscillator();
                const gainNode = avatar.audioContext.createGain();
                gainNode.gain.value = 0.001; // Nearly silent
                oscillator.connect(gainNode);
                gainNode.connect(avatar.audioContext.destination);
                oscillator.start(0);
                oscillator.stop(avatar.audioContext.currentTime + 0.1);

                // Also try playing a real Audio element with user interaction
                const silentWav = 'data:audio/wav;base64,UklGRnoGAABXQVZFZm10IBAAAAABAAEAQB8AAEAfAAABAAgAZGF0YQoGAACBhYqFbF1fdJivrJBhNjVgodDbq2EcBj+a2teleRcAGo3V5Z+HOwwgjNHqpIxDEgUvms/soZFKGQk1oc7qoZVPHg09ps3onZhTIxNFq8zklJlXJxZLrsnjj5lbKxlQsMfggJldLxxVssXdd5xfMCBZtMPZcJ1hMyNct8LVaJ5jNiZguMHSYZ5lOSljusDPWp9nPCxmvL/NVKBpPy9ov76LUaFrQjJrwL2HT6JtRTVtwbyDTKNvSDhvw7t/SaRxSjtyxLp7RqsziWPZn2EcDjqV2eWdg0AWFDmY2OKVgEYVGT+b1+CSgEsZHz+e1N2PgE8cIkKh0tqNgFMfJUSj0NeLgFciKEem0NSIgFolK0mo0NGGgF4oLkuqz86DgGErMU6sz8yBgGQuNFCu0MuAYGcxNFGv0MuAYGg0NlSx0MyAYGo3OFay0cyAYGw5OVi00s2AYG07PFq10s2AYG8+Pl290s6AYHFBQGDh4dHPm3xbJxlMq8XTeZdcMCFXtcDJX5JePihecL7HXI9gQSlibrvFWYxiRCxlcLnDVotkRy9ocbfBU4hmSjJrc7W/UYZoTTVudLO9ToRqUDhweLC7TIJsUzt0e66ySn1uVj14f6yzSH1wWUB8g6qwRntzXER/hqiuRHl1X0eCiaasPHZ3Ykl/i6SrOnR5ZU2Cjaqqe5F2XUSAipumjY51WkB8hZSifHxzcnh3hpOhem1xb3JzeZCgd2dsbW1udY6edmRpa2pscI2cc2FmaGdpa4uabF5jZWRmaImYaVtgY2FjZYaVZlhdYF5gYoOTY1VaXltdX4CQYFJYXFlbXX2OXVBVW1dYW3qLWk1TWVRWWHeIV0pQV1FTVU5GQj1AOTo7Ozk4NjY1RERPT1NSWV9ka3F4f4aNlJuiqq+1u8HGy9DV2t3g4+Xo6uvs7e3t7u7u7u7u7u7u7e3s7Ovq6Obl4+Df3NrX1NHOysfDv7u3sq6ppqKenZycm5qamZiYl5eWlpaVlZWUlJSTk5OSkpKRkZCQkI+Pjo6NjYyMi4uKioiIh4eGhoWFhISCgoGBgH9+fXx7enl4d3Z1dHNycXBvbm1sa2ppaGdmZWRjYWBfXlxbWllYV1VUUU9OTEtJSEZFQ0JAQD49OzQdBz5rn8rXrmMRBDiS0N6igj8OCjCP0eGdgkQQCjWQz+KehEUSCDmSzuGahkcTBzuVzeGYhkkVBj6Yy+GViEsVBkGay+GUiU0WBkOcyuCTik8XBEWeyuCQi1EYBEifyuCPjFMZA0mhy9+OjVUZA0uj';
                const silentAudio = new Audio(silentWav);
                silentAudio.volume = 0.01;

                await new Promise((resolve, reject) => {
                    silentAudio.oncanplaythrough = resolve;
                    silentAudio.onerror = reject;
                    setTimeout(resolve, 1000);
                });

                await silentAudio.play();
                await new Promise(r => setTimeout(r, 100));
                silentAudio.pause();

                avatar.audioContextResumed = true;

                // Check if there's failed audio queue to replay
                if (failedAudioQueue.length > 0) {
                    const totalChunks = failedAudioQueue.length;
                    audioUnlockStatus.textContent = `Playing ${totalChunks} audio chunk${totalChunks > 1 ? 's' : ''}...`;
                    audioUnlockStatus.style.color = '#00c853';
                    unlockAudioBtn.textContent = 'Audio Unlocked';
                    unlockAudioBtn.disabled = true;
                    unlockAudioBtn.classList.remove('btn-success');
                    unlockAudioBtn.classList.add('btn-secondary');

                    ttsAudioQueue = [...failedAudioQueue];
                    failedAudioQueue = [];
                    updateAudioQueueDisplay();
                    playNextAudio();
                } else {
                    audioUnlockStatus.textContent = 'Audio unlocked! Ready to play.';
                    audioUnlockStatus.style.color = '#00c853';
                    unlockAudioBtn.textContent = 'Audio Unlocked';
                    unlockAudioBtn.disabled = true;
                    unlockAudioBtn.classList.remove('btn-success');
                    unlockAudioBtn.classList.add('btn-secondary');
                }

                return true;
            } catch (e) {
                console.error('Failed to unlock audio:', e);
                audioUnlockStatus.textContent = 'Failed: ' + e.message + '. Try tapping Send.';
                audioUnlockStatus.style.color = '#e94560';
                return false;
            }
        }

        // Check if audio needs unlocking (detect mobile)
        function checkAudioStatus() {
            const isMobile = /iPhone|iPad|iPod|Android/i.test(navigator.userAgent);
            if (isMobile) {
                audioUnlockStatus.textContent = 'Tap "Unlock Audio" then "Test TTS" to enable speech';
                audioUnlockStatus.style.color = '#ffc107';
            } else {
                avatar.initAudioContext();
                if (avatar.audioContext.state === 'running') {
                    audioUnlockStatus.textContent = 'Audio ready';
                    audioUnlockStatus.style.color = '#00c853';
                }
            }
        }

        // Test TTS by fetching and playing real audio
        async function testTTSAudio() {
            try {
                audioUnlockStatus.textContent = 'Testing TTS...';
                audioUnlockStatus.style.color = '#ffc107';

                await unlockAudio();

                const ttsUrl = ttsUrlInput.value.replace(/\/$/, '') + '/api/tts';
                const response = await fetch(ttsUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ text: 'Hello! Audio is working.' })
                });

                if (!response.ok) {
                    throw new Error('TTS request failed: ' + response.status);
                }

                const audioBlob = await response.blob();
                const audioUrl = URL.createObjectURL(audioBlob);

                const testAudio = new Audio();
                testAudio.src = audioUrl;
                testAudio.volume = 1.0;
                testAudio.playsInline = true;
                testAudio.setAttribute('playsinline', '');

                testAudio.onended = () => {
                    URL.revokeObjectURL(audioUrl);
                    audioUnlockStatus.textContent = 'Audio test successful!';
                    audioUnlockStatus.style.color = '#00c853';
                };

                testAudio.onerror = (e) => {
                    console.error('Test audio error:', e);
                    audioUnlockStatus.textContent = 'Audio element error';
                    audioUnlockStatus.style.color = '#e94560';
                };

                testAudio.load();
                await testAudio.play();

                audioUnlockStatus.textContent = 'Playing test audio...';
                audioUnlockStatus.style.color = '#00c853';

            } catch (e) {
                console.error('Test TTS failed:', e);
                audioUnlockStatus.textContent = 'Test failed: ' + e.message;
                audioUnlockStatus.style.color = '#e94560';
            }
        }

        // ==================== TTS Functions ====================

        // Sentence boundary detection for streaming TTS
        function extractCompleteSentences(text) {
            // Match sentences ending with . ! ? followed by space or end
            const sentenceRegex = /[^.!?]*[.!?]+(?:\s|$)/g;
            const sentences = [];
            let match;
            let lastIndex = 0;

            while ((match = sentenceRegex.exec(text)) !== null) {
                sentences.push(match[0].trim());
                lastIndex = sentenceRegex.lastIndex;
            }

            // Return sentences found and remaining text
            const remaining = text.slice(lastIndex);
            return { sentences, remaining };
        }

        // Queue audio for playback with sequence ordering
        function queueTTSAudio(audioBlob, sentenceText, sequenceNum) {
            const audioUrl = URL.createObjectURL(audioBlob);
            const item = { url: audioUrl, text: sentenceText, seq: sequenceNum };

            // If this is the next expected sequence, add to queue directly
            if (sequenceNum === nextExpectedSequence) {
                ttsAudioQueue.push(item);
                nextExpectedSequence++;

                // Check if we have any pending items that can now be added
                while (pendingAudioItems.has(nextExpectedSequence)) {
                    ttsAudioQueue.push(pendingAudioItems.get(nextExpectedSequence));
                    pendingAudioItems.delete(nextExpectedSequence);
                    nextExpectedSequence++;
                }

                updateAudioQueueDisplay();

                if (!isPlayingAudio) {
                    playNextAudio();
                }
            } else if (sequenceNum > nextExpectedSequence) {
                // Out of order - store for later
                console.log(`Audio seq ${sequenceNum} arrived out of order, expecting ${nextExpectedSequence}`);
                pendingAudioItems.set(sequenceNum, item);
            } else {
                // Old sequence number (shouldn't happen, but handle it)
                console.warn(`Ignoring old audio sequence ${sequenceNum}, already at ${nextExpectedSequence}`);
                URL.revokeObjectURL(audioUrl);
            }
        }

        // Play next audio in queue
        async function playNextAudio() {
            if (ttsAudioQueue.length === 0) {
                isPlayingAudio = false;
                avatar.stopSpeaking();
                setTTSStatus('TTS idle');
                return;
            }

            isPlayingAudio = true;
            const item = ttsAudioQueue.shift();
            updateAudioQueueDisplay();

            setTTSStatus(`Speaking: "${item.text.slice(0, 50)}${item.text.length > 50 ? '...' : ''}"`);

            // Create audio element - simple approach for maximum compatibility
            currentAudio = new Audio();
            currentAudio.src = item.url;
            currentAudio.volume = 1.0;
            currentAudio.playsInline = true; // Required for mobile Chrome
            currentAudio.setAttribute('playsinline', ''); // Also set as attribute

            // Try to use analyser for lip sync, but don't require it
            let useAnalyser = false;
            try {
                avatar.initAudioContext();
                await avatar.resumeAudioContext();

                // Only try MediaElementSource on desktop or if explicitly unlocked
                if (avatar.audioContextResumed && avatar.audioContext.state === 'running') {
                    useAnalyser = avatar.connectAudioElement(currentAudio);
                }
            } catch (e) {
                console.warn('Audio analyser not available, using fallback animation:', e);
                useAnalyser = false;
            }

            // Start mouth animation (will use analyser if available, fallback otherwise)
            avatar.startSpeaking(useAnalyser);

            currentAudio.onended = () => {
                URL.revokeObjectURL(item.url);
                currentAudio = null;
                // Don't stop animation yet if more audio is queued
                if (ttsAudioQueue.length === 0) {
                    avatar.stopSpeaking();
                }
                playNextAudio();
            };

            currentAudio.onerror = (e) => {
                console.error('Audio playback error:', e);
                audioUnlockStatus.textContent = 'Audio error - try Unlock Audio button';
                audioUnlockStatus.style.color = '#e94560';
                URL.revokeObjectURL(item.url);
                currentAudio = null;
                avatar.stopSpeaking();
                playNextAudio();
            };

            try {
                // Use load() then play() for better mobile compatibility
                currentAudio.load();
                await currentAudio.play();
                // Clear any failed queue on success
                failedAudioQueue = [];
            } catch (err) {
                console.error('Failed to play audio:', err);
                setTTSStatus(`Audio error - tap Unlock Audio to retry`, true);

                // Save the ENTIRE queue for retry (current item + remaining queue)
                failedAudioQueue = [{ url: item.url, text: item.text, seq: item.seq }, ...ttsAudioQueue];
                ttsAudioQueue = []; // Clear the main queue since it's saved in failedAudioQueue

                const totalChunks = failedAudioQueue.length;
                audioUnlockStatus.textContent = `Tap "Unlock Audio" to play ${totalChunks} audio chunk${totalChunks > 1 ? 's' : ''}`;
                audioUnlockStatus.style.color = '#ffc107';

                // Re-enable unlock button
                unlockAudioBtn.disabled = false;
                unlockAudioBtn.textContent = 'Unlock Audio';
                unlockAudioBtn.classList.remove('btn-secondary');
                unlockAudioBtn.classList.add('btn-success');

                avatar.stopSpeaking();
                isPlayingAudio = false;
                updateAudioQueueDisplay();
                // Don't call playNextAudio - wait for user to unlock
            }
        }

        // Stop all TTS playback
        function stopTTS() {
            if (currentAudio) {
                currentAudio.pause();
                currentAudio = null;
            }
            ttsAudioQueue.forEach(item => URL.revokeObjectURL(item.url));
            ttsAudioQueue = [];
            isPlayingAudio = false;
            pendingSentence = '';
            avatar.stopSpeaking();
            updateAudioQueueDisplay();
            setTTSStatus('TTS stopped');
        }

        // Update audio queue display
        function updateAudioQueueDisplay() {
            audioQueue.innerHTML = '';
            if (isPlayingAudio) {
                const playing = document.createElement('span');
                playing.className = 'audio-chunk playing';
                playing.textContent = 'â–¶ Playing';
                audioQueue.appendChild(playing);
            }
            ttsAudioQueue.forEach((item, i) => {
                const chunk = document.createElement('span');
                chunk.className = 'audio-chunk queued';
                chunk.textContent = `${i + 1}: ${item.text.slice(0, 20)}...`;
                audioQueue.appendChild(chunk);
            });
        }

        // Set TTS status
        function setTTSStatus(message, isError = false) {
            ttsStatus.textContent = message;
            ttsStatus.className = 'tts-status' + (isError ? ' error' : (isPlayingAudio ? ' speaking' : ''));
        }

        // Synthesize speech using Piper TTS API (via proxy)
        async function synthesizeSpeech(text) {
            if (!text.trim()) return null;

            const startTime = performance.now();

            try {
                // Use proxied TTS endpoint to avoid CORS issues
                // Server proxies /tts/* to http://localhost:7860/*
                const ttsUrl = ttsUrlInput.value;
                const apiUrl = ttsUrl.replace(/\/$/, '') + '/api/tts';

                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        text: text
                    }),
                });

                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`TTS API error: ${response.status} - ${errorText}`);
                }

                // Piper returns WAV audio directly
                const blob = await response.blob();

                const latency = performance.now() - startTime;
                statTTSLatency.textContent = `${latency.toFixed(0)} ms`;
                return blob;

            } catch (err) {
                console.error('TTS synthesis error:', err);
                setTTSStatus(`TTS error: ${err.message}`, true);
                return null;
            }
        }

        // Process text for TTS (streaming or batch)
        async function processTextForTTS(newContent, isComplete = false) {
            if (!ttsEnabled.checked) return;

            pendingSentence += newContent;

            if (ttsStreaming.checked) {
                // Streaming mode: synthesize complete sentences as they arrive
                const { sentences, remaining } = extractCompleteSentences(pendingSentence);
                pendingSentence = remaining;

                // Launch all TTS requests in parallel but with assigned sequence numbers
                const synthesisPromises = sentences
                    .filter(s => s.trim().length > 2)
                    .map(sentence => {
                        const seqNum = ttsSequenceNumber++;
                        sentenceCount++;
                        statSentences.textContent = sentenceCount.toString();
                        setTTSStatus(`Synthesizing: "${sentence.slice(0, 30)}..."`);

                        return synthesizeSpeech(sentence).then(audioBlob => {
                            if (audioBlob) {
                                queueTTSAudio(audioBlob, sentence, seqNum);
                            }
                        });
                    });

                // Wait for all to complete (but they'll be queued in order due to sequence numbers)
                await Promise.all(synthesisPromises);
            }

            // On completion, synthesize any remaining text
            if (isComplete && pendingSentence.trim().length > 2) {
                const seqNum = ttsSequenceNumber++;
                if (!ttsStreaming.checked) {
                    // Batch mode: synthesize all at once
                    setTTSStatus('Synthesizing full response...');
                    const audioBlob = await synthesizeSpeech(pendingSentence);
                    if (audioBlob) {
                        sentenceCount++;
                        statSentences.textContent = sentenceCount.toString();
                        queueTTSAudio(audioBlob, pendingSentence, seqNum);
                    }
                } else {
                    // Streaming mode: synthesize remaining fragment
                    sentenceCount++;
                    statSentences.textContent = sentenceCount.toString();
                    const audioBlob = await synthesizeSpeech(pendingSentence);
                    if (audioBlob) {
                        queueTTSAudio(audioBlob, pendingSentence, seqNum);
                    }
                }
                pendingSentence = '';
            }
        }

        // ==================== Camera Functions ====================

        function checkSecureContext() {
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                const isSecure = window.isSecureContext;
                const protocol = window.location.protocol;
                const hostname = window.location.hostname;

                let msg = 'Camera API not available. ';
                if (!isSecure) {
                    msg += `Requires HTTPS or localhost. Current: ${protocol}//${hostname}`;
                }

                console.error(msg);
                cameraSelect.innerHTML = '<option value="">Camera requires HTTPS</option>';
                setStatus(msg, 'error');

                responseBox.innerHTML = `<strong>Camera Access Blocked</strong>\n\n` +
                    `Browsers require HTTPS for camera access (except localhost).\n\n` +
                    `<strong>Options:</strong>\n` +
                    `1. Access from the Jetson directly: http://localhost:8443\n` +
                    `2. Use Chrome with security flag\n` +
                    `3. Accept the self-signed certificate\n\n` +
                    `Current URL: ${window.location.href}\n` +
                    `Secure context: ${isSecure ? 'Yes' : 'No'}`;
                return false;
            }
            return true;
        }

        async function enumerateCameras() {
            if (!checkSecureContext()) return;

            try {
                await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
                const devices = await navigator.mediaDevices.enumerateDevices();
                const videoDevices = devices.filter(d => d.kind === 'videoinput');

                cameraSelect.innerHTML = '';

                if (videoDevices.length === 0) {
                    cameraSelect.innerHTML = '<option value="">No cameras found</option>';
                    setStatus('No cameras found', 'error');
                    return;
                }

                videoDevices.forEach((device, index) => {
                    const option = document.createElement('option');
                    option.value = device.deviceId;
                    option.textContent = device.label || `Camera ${index + 1}`;
                    cameraSelect.appendChild(option);
                });

                selectedDeviceId = videoDevices[0].deviceId;
                setStatus(`Found ${videoDevices.length} camera(s)`, 'success');
            } catch (err) {
                console.error('Error enumerating cameras:', err);
                cameraSelect.innerHTML = '<option value="">Camera access denied</option>';
                setStatus('Camera access denied: ' + err.message, 'error');
            }
        }

        async function initWebcam() {
            if (!checkSecureContext()) return;

            try {
                if (stream) {
                    stream.getTracks().forEach(track => track.stop());
                }

                const res = resolutionPresets[resolutionSelect.value];
                currentResolution = { width: res.width, height: res.height };

                const constraints = {
                    video: {
                        width: { ideal: res.width },
                        height: { ideal: res.height }
                    },
                    audio: false
                };

                if (selectedDeviceId) {
                    constraints.video.deviceId = { exact: selectedDeviceId };
                }

                stream = await navigator.mediaDevices.getUserMedia(constraints);
                webcam.srcObject = stream;
                updateResolutionInfo();
                setStatus('Camera ready', 'success');
            } catch (err) {
                console.error('Webcam error:', err);
                setStatus('Failed to access camera: ' + err.message, 'error');
            }
        }

        function updateResolutionInfo() {
            const res = resolutionPresets[resolutionSelect.value];
            resolutionInfo.textContent = `Target: ${res.width}x${res.height} | Est. payload: ~${res.estKB}KB`;
        }

        cameraSelect.addEventListener('change', async () => {
            selectedDeviceId = cameraSelect.value;
            await initWebcam();
        });

        resolutionSelect.addEventListener('change', async () => {
            updateResolutionInfo();
            await initWebcam();
        });

        function captureFrame() {
            const res = resolutionPresets[resolutionSelect.value];
            canvas.width = res.width;
            canvas.height = res.height;

            const ctx = canvas.getContext('2d');
            ctx.drawImage(webcam, 0, 0, res.width, res.height);

            const quality = res.width <= 640 ? 0.85 : 0.75;
            const dataUrl = canvas.toDataURL('image/jpeg', quality);

            snapshot.src = dataUrl;
            snapshot.classList.remove('hidden');

            return dataUrl;
        }

        // ==================== Status & Stats ====================

        function setStatus(message, type = '') {
            statusBar.textContent = message;
            statusBar.className = 'status-bar';
            if (type) {
                statusBar.classList.add(type);
            }
        }

        function updateStats(stats) {
            if (stats.ttft !== undefined) {
                statTTFT.textContent = `${stats.ttft.toFixed(0)} ms`;
                statTTFT.className = 'stat-value' + (stats.ttft > 2000 ? ' warning' : stats.ttft > 5000 ? ' error' : '');
            }
            if (stats.latency !== undefined) {
                statLatency.textContent = `${(stats.latency / 1000).toFixed(2)} s`;
            }
            if (stats.tps !== undefined) {
                statTPS.textContent = stats.tps.toFixed(1);
                statTPS.className = 'stat-value' + (stats.tps > 20 ? ' highlight' : stats.tps < 5 ? ' warning' : '');
            }
            statRequests.textContent = requestCount.toString();
        }

        function resetStats() {
            statTTFT.textContent = '...';
            statLatency.textContent = '...';
            statTPS.textContent = '...';
            statTTSLatency.textContent = '--';
        }

        // ==================== Main LLM Function ====================

        async function sendToLLM() {
            if (isProcessing) {
                console.log('Already processing, skipping...');
                return;
            }

            const prompt = promptInput.value.trim();
            if (!prompt) {
                setStatus('Please enter a prompt', 'error');
                return;
            }

            // Reset TTS state for new request
            stopTTS();
            pendingSentence = '';
            ttsSequenceNumber = 0;
            nextExpectedSequence = 0;
            pendingAudioItems.clear();

            isProcessing = true;
            sendBtn.disabled = true;
            resetStats();
            setStatus('Capturing and sending...', 'loading');

            // Start thinking animation while waiting for LLM
            avatar.startThinking();

            const startTime = performance.now();
            let firstTokenTime = null;
            let tokenCount = 0;

            try {
                const imageDataUrl = captureFrame();
                const apiUrl = apiUrlInput.value;
                const modelName = modelNameInput.value;

                const requestBody = {
                    model: modelName,
                    messages: [
                        {
                            role: "user",
                            content: [
                                {
                                    type: "image_url",
                                    image_url: { url: imageDataUrl }
                                },
                                {
                                    type: "text",
                                    text: prompt
                                }
                            ]
                        }
                    ],
                    max_tokens: 256,
                    temperature: 0.7,
                    stream: true
                };

                requestCount++;
                updateStats({});

                setStatus('Thinking...', 'loading');
                responseBox.innerHTML = '<span class="streaming-indicator"></span>';

                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(requestBody)
                });

                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`API error ${response.status}: ${errorText}`);
                }

                const reader = response.body.getReader();
                const decoder = new TextDecoder();
                let fullResponse = '';

                while (true) {
                    const { done, value } = await reader.read();
                    if (done) break;

                    const chunk = decoder.decode(value, { stream: true });
                    const lines = chunk.split('\n');

                    for (const line of lines) {
                        if (line.startsWith('data: ')) {
                            const data = line.slice(6);
                            if (data === '[DONE]') continue;

                            try {
                                const json = JSON.parse(data);
                                const content = json.choices?.[0]?.delta?.content;
                                if (content) {
                                    if (firstTokenTime === null) {
                                        firstTokenTime = performance.now();
                                        const ttft = firstTokenTime - startTime;
                                        updateStats({ ttft });
                                        // Stop thinking animation when first token arrives
                                        avatar.stopThinking();
                                        setStatus('Responding...', 'loading');
                                    }

                                    fullResponse += content;
                                    tokenCount++;
                                    responseBox.textContent = fullResponse;

                                    // Process for TTS (streaming)
                                    processTextForTTS(content, false);

                                    if (tokenCount % 5 === 0) {
                                        const elapsed = performance.now() - firstTokenTime;
                                        const tps = tokenCount / (elapsed / 1000);
                                        updateStats({ tps });
                                    }
                                }
                            } catch (e) {
                                // Ignore parse errors
                            }
                        }
                    }
                }

                // Final stats
                const endTime = performance.now();
                const totalLatency = endTime - startTime;
                const generationTime = firstTokenTime ? endTime - firstTokenTime : totalLatency;
                const finalTPS = tokenCount > 0 ? tokenCount / (generationTime / 1000) : 0;

                updateStats({ latency: totalLatency, tps: finalTPS });

                // Process remaining text for TTS
                await processTextForTTS('', true);

                if (!fullResponse) {
                    responseBox.textContent = 'No response received';
                }

                const timestamp = new Date().toLocaleTimeString();
                setStatus(`Response received at ${timestamp} (${tokenCount} tokens)`, 'success');

            } catch (err) {
                console.error('LLM error:', err);
                responseBox.textContent = 'Error: ' + err.message;
                setStatus('Error: ' + err.message, 'error');
                // Stop thinking animation on error
                avatar.stopThinking();
            } finally {
                isProcessing = false;
                sendBtn.disabled = false;
                // Make sure thinking is stopped
                if (avatar.isThinking) {
                    avatar.stopThinking();
                }
            }
        }

        // ==================== Autosend ====================

        function toggleAutosend() {
            if (isAutosending) {
                clearInterval(autosendInterval);
                autosendInterval = null;
                isAutosending = false;
                autosendBtn.textContent = 'Start Autosend';
                autosendBtn.classList.remove('btn-danger');
                autosendBtn.classList.add('btn-success');
                intervalInput.disabled = false;
                setStatus('Autosend stopped', 'success');
            } else {
                const interval = parseInt(intervalInput.value) || 5000;
                if (interval < 500) {
                    setStatus('Interval must be at least 500ms', 'error');
                    return;
                }

                isAutosending = true;
                autosendBtn.textContent = 'Stop Autosend';
                autosendBtn.classList.remove('btn-success');
                autosendBtn.classList.add('btn-danger');
                intervalInput.disabled = true;

                sendToLLM();
                autosendInterval = setInterval(() => {
                    if (!isProcessing && !isPlayingAudio) {
                        sendToLLM();
                    }
                }, interval);

                setStatus(`Autosend active (every ${interval}ms)`, 'success');
            }
        }

        // ==================== Event Listeners ====================

        // Initialize audio context on first user interaction (required for mobile)
        function initAudioOnInteraction() {
            avatar.initAudioContext();
            avatar.resumeAudioContext();
        }

        sendBtn.addEventListener('click', () => {
            initAudioOnInteraction();
            sendToLLM();
        });
        autosendBtn.addEventListener('click', () => {
            initAudioOnInteraction();
            toggleAutosend();
        });
        stopTtsBtn.addEventListener('click', stopTTS);
        unlockAudioBtn.addEventListener('click', unlockAudio);
        testAudioBtn.addEventListener('click', testTTSAudio);

        promptInput.addEventListener('keydown', (e) => {
            if (e.ctrlKey && e.key === 'Enter') {
                initAudioOnInteraction();
                sendToLLM();
            }
        });

        // ==================== Initialization ====================

        function setDefaultUrls() {
            const origin = window.location.origin;
            apiUrlInput.value = `${origin}/v1/chat/completions`;
            // TTS proxied through /tts/* on same origin
            ttsUrlInput.value = `${origin}/tts`;
        }

        async function init() {
            setDefaultUrls();
            // Create the avatar (it starts blink and idle animations automatically)
            avatar = new Avatar('#avatarContainer');
            await enumerateCameras();
            await initWebcam();
            // Check audio status for mobile
            checkAudioStatus();
        }

        init();
    </script>
</body>
</html>
